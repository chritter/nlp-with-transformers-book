{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run this cell if you're on Colab or Kaggle\n",
    "# !git clone https://github.com/nlp-with-transformers/notebooks.git\n",
    "# %cd notebooks\n",
    "# from install import *\n",
    "# install_requirements(is_chapter6=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#from utils import *\n",
    "#setup_chapter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-19 10:02:56.531981: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-19 10:02:56.578185: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-19 10:02:56.578218: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-19 10:02:56.579247: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-19 10:02:56.586027: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-19 10:02:57.500708: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from transformers import pipeline, set_seed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The CNN/DailyMail Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.17.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datasets\n",
    "datasets.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: ['article', 'highlights', 'id']\n"
     ]
    }
   ],
   "source": [
    "#hide_output\n",
    "from datasets import load_dataset\n",
    "\n",
    "#dataset = load_dataset(\"cnn_dailymail\", version=\"3.0.0\")\n",
    "dataset = load_dataset(\"cnn_dailymail\", version=\"3.0.0\", data_files={\"train\": '3.0.0/train*.parquet', \"test\": '3.0.0/test*.parquet'})\n",
    "print(f\"Features: {dataset['train'].column_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['article', 'highlights', 'id'],\n",
       "        num_rows: 287113\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['article', 'highlights', 'id'],\n",
       "        num_rows: 11490\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Article (excerpt of 500 characters, total length: 4051):\n",
      "\n",
      "Editor's note: In our Behind the Scenes series, CNN correspondents share their experiences in covering news and analyze the stories behind the events. Here, Soledad O'Brien takes users inside a jail where many of the inmates are mentally ill. An inmate housed on the \"forgotten floor,\" where many mentally ill inmates are housed in Miami before trial. MIAMI, Florida (CNN) -- The ninth floor of the Miami-Dade pretrial detention facility is dubbed the \"forgotten floor.\" Here, inmates with the most s\n",
      "\n",
      "Summary (length: 281):\n",
      "Mentally ill inmates in Miami are housed on the \"forgotten floor\"\n",
      "Judge Steven Leifman says most are there as a result of \"avoidable felonies\"\n",
      "While CNN tours facility, patient shouts: \"I am the son of the president\"\n",
      "Leifman says the system is unjust and he's fighting for change .\n"
     ]
    }
   ],
   "source": [
    "sample = dataset[\"train\"][1]\n",
    "print(f\"\"\"\n",
    "Article (excerpt of 500 characters, total length: {len(sample[\"article\"])}):\n",
    "\"\"\")\n",
    "print(sample[\"article\"][:500])\n",
    "print(f'\\nSummary (length: {len(sample[\"highlights\"])}):')\n",
    "print(sample[\"highlights\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Summarization Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = dataset[\"train\"][1][\"article\"][:2000]\n",
    "# We'll collect the generated summaries of each model in a dictionary\n",
    "summaries = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /teamspace/studios/this_studio/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide_output\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The U.S. are a country.', 'The U.N. is an organization.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = \"The U.S. are a country. The U.N. is an organization.\"\n",
    "sent_tokenize(string)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarization Baseline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def three_sentence_summary(text):\n",
    "    return \"\\n\".join(sent_tokenize(text)[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries[\"baseline\"] = three_sentence_summary(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide_output\n",
    "from transformers import pipeline, set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "459eb379705f4ecc82356ddbf45e3648",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.09k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "137a8e2e93db4ce0813ba4b6a8ecd22d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.12G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "948ad922d0f944f5a6d424c3873c4e7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/88.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2e9362baab4402cbe55a3ec9372475d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.82M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a62a297b6794ef88f1e1851f230ffbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/65.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "#hide_output\n",
    "pipe = pipeline(\"summarization\", model=\"google/pegasus-cnn_dailymail\")\n",
    "pipe_out = pipe(sample_text)\n",
    "summaries[\"pegasus\"] = pipe_out[0][\"summary_text\"].replace(\" .<n>\", \".\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_107109/2973086757.py:4: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  bleu_metric = load_metric(\"sacrebleu\")\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/datasets/load.py:753: FutureWarning: The repository for sacrebleu contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.17.0/metrics/sacrebleu/sacrebleu.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# hide_output\n",
    "from datasets import load_metric\n",
    "\n",
    "bleu_metric = load_metric(\"sacrebleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu_metric = evaluate.load(\"sacrebleu\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* implementation uses NGRAM_ORDER = 4, up to 4-gram\n",
    "* smoothing https://aclanthology.org/W14-3346/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROUGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/datasets/load.py:753: FutureWarning: The repository for rouge contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.17.0/metrics/rouge/rouge.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# hide_output\n",
    "rouge_metric = load_metric(\"rouge\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating PEGASUS on the CNN/DailyMail Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "At least one data file must be specified, but got data_files=None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdatasets\u001b[39;00m \u001b[39mimport\u001b[39;00m load_dataset, load_metric\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m AutoModelForSeq2SeqLM, AutoTokenizer\n\u001b[0;32m----> 8\u001b[0m dataset \u001b[39m=\u001b[39m load_dataset(\u001b[39m\"\u001b[39;49m\u001b[39mcnn_dailymail\u001b[39;49m\u001b[39m\"\u001b[39;49m, version\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m3.0.0\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      9\u001b[0m rouge_metric \u001b[39m=\u001b[39m load_metric(\u001b[39m\"\u001b[39m\u001b[39mrouge\u001b[39m\u001b[39m\"\u001b[39m, cache_dir\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m     10\u001b[0m rouge_names \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mrouge1\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mrouge2\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mrougeL\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mrougeLsum\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/datasets/load.py:2574\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, token, use_auth_token, task, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001b[0m\n\u001b[1;32m   2571\u001b[0m try_from_hf_gcs \u001b[39m=\u001b[39m path \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m _PACKAGED_DATASETS_MODULES\n\u001b[1;32m   2573\u001b[0m \u001b[39m# Download and prepare data\u001b[39;00m\n\u001b[0;32m-> 2574\u001b[0m builder_instance\u001b[39m.\u001b[39;49mdownload_and_prepare(\n\u001b[1;32m   2575\u001b[0m     download_config\u001b[39m=\u001b[39;49mdownload_config,\n\u001b[1;32m   2576\u001b[0m     download_mode\u001b[39m=\u001b[39;49mdownload_mode,\n\u001b[1;32m   2577\u001b[0m     verification_mode\u001b[39m=\u001b[39;49mverification_mode,\n\u001b[1;32m   2578\u001b[0m     try_from_hf_gcs\u001b[39m=\u001b[39;49mtry_from_hf_gcs,\n\u001b[1;32m   2579\u001b[0m     num_proc\u001b[39m=\u001b[39;49mnum_proc,\n\u001b[1;32m   2580\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m   2581\u001b[0m )\n\u001b[1;32m   2583\u001b[0m \u001b[39m# Build dataset for splits\u001b[39;00m\n\u001b[1;32m   2584\u001b[0m keep_in_memory \u001b[39m=\u001b[39m (\n\u001b[1;32m   2585\u001b[0m     keep_in_memory \u001b[39mif\u001b[39;00m keep_in_memory \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m is_small_dataset(builder_instance\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mdataset_size)\n\u001b[1;32m   2586\u001b[0m )\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/datasets/builder.py:1005\u001b[0m, in \u001b[0;36mDatasetBuilder.download_and_prepare\u001b[0;34m(self, output_dir, download_config, download_mode, verification_mode, ignore_verifications, try_from_hf_gcs, dl_manager, base_path, use_auth_token, file_format, max_shard_size, num_proc, storage_options, **download_and_prepare_kwargs)\u001b[0m\n\u001b[1;32m   1003\u001b[0m     \u001b[39mif\u001b[39;00m num_proc \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1004\u001b[0m         prepare_split_kwargs[\u001b[39m\"\u001b[39m\u001b[39mnum_proc\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m num_proc\n\u001b[0;32m-> 1005\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_download_and_prepare(\n\u001b[1;32m   1006\u001b[0m         dl_manager\u001b[39m=\u001b[39;49mdl_manager,\n\u001b[1;32m   1007\u001b[0m         verification_mode\u001b[39m=\u001b[39;49mverification_mode,\n\u001b[1;32m   1008\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mprepare_split_kwargs,\n\u001b[1;32m   1009\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mdownload_and_prepare_kwargs,\n\u001b[1;32m   1010\u001b[0m     )\n\u001b[1;32m   1011\u001b[0m \u001b[39m# Sync info\u001b[39;00m\n\u001b[1;32m   1012\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mdataset_size \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(split\u001b[39m.\u001b[39mnum_bytes \u001b[39mfor\u001b[39;00m split \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39msplits\u001b[39m.\u001b[39mvalues())\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/datasets/builder.py:1078\u001b[0m, in \u001b[0;36mDatasetBuilder._download_and_prepare\u001b[0;34m(self, dl_manager, verification_mode, **prepare_split_kwargs)\u001b[0m\n\u001b[1;32m   1076\u001b[0m split_dict \u001b[39m=\u001b[39m SplitDict(dataset_name\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset_name)\n\u001b[1;32m   1077\u001b[0m split_generators_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_split_generators_kwargs(prepare_split_kwargs)\n\u001b[0;32m-> 1078\u001b[0m split_generators \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_split_generators(dl_manager, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msplit_generators_kwargs)\n\u001b[1;32m   1080\u001b[0m \u001b[39m# Checksums verification\u001b[39;00m\n\u001b[1;32m   1081\u001b[0m \u001b[39mif\u001b[39;00m verification_mode \u001b[39m==\u001b[39m VerificationMode\u001b[39m.\u001b[39mALL_CHECKS \u001b[39mand\u001b[39;00m dl_manager\u001b[39m.\u001b[39mrecord_checksums:\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/datasets/packaged_modules/parquet/parquet.py:42\u001b[0m, in \u001b[0;36mParquet._split_generators\u001b[0;34m(self, dl_manager)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"We handle string, list and dicts in datafiles\"\"\"\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mdata_files:\n\u001b[0;32m---> 42\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAt least one data file must be specified, but got data_files=\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mdata_files\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     43\u001b[0m data_files \u001b[39m=\u001b[39m dl_manager\u001b[39m.\u001b[39mdownload_and_extract(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mdata_files)\n\u001b[1;32m     44\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_files, (\u001b[39mstr\u001b[39m, \u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)):\n",
      "\u001b[0;31mValueError\u001b[0m: At least one data file must be specified, but got data_files=None"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "# ignore this cell it is only to be able to start running the notebook here\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from datasets import load_dataset, load_metric\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "dataset = load_dataset(\"cnn_dailymail\", version=\"3.0.0\")\n",
    "rouge_metric = load_metric(\"rouge\", cache_dir=None)\n",
    "rouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_summaries_baseline(dataset, metric,\n",
    "                                column_text=\"article\", \n",
    "                                column_summary=\"highlights\"):\n",
    "    summaries = [three_sentence_summary(text) for text in dataset[column_text]]\n",
    "    metric.add_batch(predictions=summaries,\n",
    "                     references=dataset[column_summary])    \n",
    "    score = metric.compute()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['article', 'highlights', 'id'],\n",
       "        num_rows: 287113\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['article', 'highlights', 'id'],\n",
       "        num_rows: 11490\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sampled = dataset[\"test\"].shuffle(seed=42).select(range(1000))\n",
    "\n",
    "#score = evaluate_summaries_baseline(test_sampled, rouge_metric)\n",
    "#rouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)\n",
    "#pd.DataFrame.from_dict(rouge_dict, orient=\"index\", columns=[\"baseline\"]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "def chunks(list_of_elements, batch_size):\n",
    "    \"\"\"Yield successive batch-sized chunks from list_of_elements.\"\"\"\n",
    "    for i in range(0, len(list_of_elements), batch_size):\n",
    "        yield list_of_elements[i : i + batch_size]\n",
    "\n",
    "def evaluate_summaries_pegasus(dataset, metric, model, tokenizer, \n",
    "                               batch_size=16, device=device, \n",
    "                               column_text=\"article\", \n",
    "                               column_summary=\"highlights\"):\n",
    "    article_batches = list(chunks(dataset[column_text], batch_size))\n",
    "    target_batches = list(chunks(dataset[column_summary], batch_size))\n",
    "\n",
    "    for article_batch, target_batch in tqdm(\n",
    "        zip(article_batches, target_batches), total=len(article_batches)):\n",
    "        \n",
    "        inputs = tokenizer(article_batch, max_length=1024,  truncation=True, \n",
    "                        padding=\"max_length\", return_tensors=\"pt\")\n",
    "        \n",
    "        summaries = model.generate(input_ids=inputs[\"input_ids\"].to(device),\n",
    "                         attention_mask=inputs[\"attention_mask\"].to(device), \n",
    "                         length_penalty=0.8, num_beams=8, max_length=128)\n",
    "        \n",
    "        decoded_summaries = [tokenizer.decode(s, skip_special_tokens=True, \n",
    "                                clean_up_tokenization_spaces=True) \n",
    "               for s in summaries]\n",
    "        decoded_summaries = [d.replace(\"<n>\", \" \") for d in decoded_summaries]\n",
    "        metric.add_batch(predictions=decoded_summaries, references=target_batch)\n",
    "        \n",
    "    score = metric.compute()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# hide_output\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "model_ckpt = \"google/pegasus-cnn_dailymail\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt).to(device)\n",
    "# score = evaluate_summaries_pegasus(test_sampled, rouge_metric, \n",
    "#                                    model, tokenizer, batch_size=8)\n",
    "# rouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)\n",
    "# pd.DataFrame(rouge_dict, index=[\"pegasus\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pegasus</th>\n",
       "      <td>0.389276</td>\n",
       "      <td>0.171296</td>\n",
       "      <td>0.245061</td>\n",
       "      <td>0.354239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           rouge1    rouge2    rougeL  rougeLsum\n",
       "pegasus  0.389276  0.171296  0.245061   0.354239"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hide_input \n",
    "pd.DataFrame(rouge_dict, index=[\"pegasus\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Summarization Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split lengths: [14732, 819, 818]\n",
      "Features: ['id', 'dialogue', 'summary']\n",
      "\n",
      "Dialogue:\n",
      "Hannah: Hey, do you have Betty's number?\n",
      "Amanda: Lemme check\n",
      "Hannah: <file_gif>\n",
      "Amanda: Sorry, can't find it.\n",
      "Amanda: Ask Larry\n",
      "Amanda: He called her last time we were at the park together\n",
      "Hannah: I don't know him well\n",
      "Hannah: <file_gif>\n",
      "Amanda: Don't be shy, he's very nice\n",
      "Hannah: If you say so..\n",
      "Hannah: I'd rather you texted him\n",
      "Amanda: Just text him 🙂\n",
      "Hannah: Urgh.. Alright\n",
      "Hannah: Bye\n",
      "Amanda: Bye bye\n",
      "\n",
      "Summary:\n",
      "Hannah needs Betty's number but Amanda doesn't have it. She needs to contact Larry.\n"
     ]
    }
   ],
   "source": [
    "# hide_output\n",
    "dataset_samsum = load_dataset(\"samsum\")\n",
    "split_lengths = [len(dataset_samsum[split])for split in dataset_samsum]\n",
    "\n",
    "print(f\"Split lengths: {split_lengths}\")\n",
    "print(f\"Features: {dataset_samsum['train'].column_names}\")\n",
    "print(\"\\nDialogue:\")\n",
    "print(dataset_samsum[\"test\"][0][\"dialogue\"])\n",
    "print(\"\\nSummary:\")\n",
    "print(dataset_samsum[\"test\"][0][\"summary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split lengths: [14732, 819, 818]\n",
      "Features: ['id', 'dialogue', 'summary']\n",
      "\n",
      "Dialogue:\n",
      "Hannah: Hey, do you have Betty's number?\n",
      "Amanda: Lemme check\n",
      "Hannah: <file_gif>\n",
      "Amanda: Sorry, can't find it.\n",
      "Amanda: Ask Larry\n",
      "Amanda: He called her last time we were at the park together\n",
      "Hannah: I don't know him well\n",
      "Hannah: <file_gif>\n",
      "Amanda: Don't be shy, he's very nice\n",
      "Hannah: If you say so..\n",
      "Hannah: I'd rather you texted him\n",
      "Amanda: Just text him 🙂\n",
      "Hannah: Urgh.. Alright\n",
      "Hannah: Bye\n",
      "Amanda: Bye bye\n",
      "\n",
      "Summary:\n",
      "Hannah needs Betty's number but Amanda doesn't have it. She needs to contact Larry.\n"
     ]
    }
   ],
   "source": [
    "# hide_input\n",
    "print(f\"Split lengths: {split_lengths}\")\n",
    "print(f\"Features: {dataset_samsum['train'].column_names}\")\n",
    "print(\"\\nDialogue:\")\n",
    "print(dataset_samsum[\"test\"][0][\"dialogue\"])\n",
    "print(\"\\nSummary:\")\n",
    "print(dataset_samsum[\"test\"][0][\"summary\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating PEGASUS on SAMSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pipe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pipe_out \u001b[39m=\u001b[39m pipe(dataset_samsum[\u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mdialogue\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m      2\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mSummary:\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(pipe_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39msummary_text\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m .<n>\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pipe' is not defined"
     ]
    }
   ],
   "source": [
    "pipe_out = pipe(dataset_samsum[\"test\"][0][\"dialogue\"])\n",
    "print(\"Summary:\")\n",
    "print(pipe_out[0][\"summary_text\"].replace(\" .<n>\", \".\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/103 [00:04<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacty of 14.75 GiB of which 9.06 MiB is free. Process 158553 has 14.74 GiB memory in use. Of the allocated memory 13.52 GiB is allocated by PyTorch, and 213.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[75], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# hide_output\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m score \u001b[39m=\u001b[39m evaluate_summaries_pegasus(dataset_samsum[\u001b[39m\"\u001b[39;49m\u001b[39mtest\u001b[39;49m\u001b[39m\"\u001b[39;49m], rouge_metric, model,\n\u001b[1;32m      3\u001b[0m                                    tokenizer, column_text\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mdialogue\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      4\u001b[0m                                    column_summary\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msummary\u001b[39;49m\u001b[39m\"\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m8\u001b[39;49m)\n\u001b[1;32m      6\u001b[0m rouge_dict \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m((rn, score[rn]\u001b[39m.\u001b[39mmid\u001b[39m.\u001b[39mfmeasure) \u001b[39mfor\u001b[39;00m rn \u001b[39min\u001b[39;00m rouge_names)\n\u001b[1;32m      7\u001b[0m pd\u001b[39m.\u001b[39mDataFrame(rouge_dict, index\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mpegasus\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "Cell \u001b[0;32mIn[71], line 24\u001b[0m, in \u001b[0;36mevaluate_summaries_pegasus\u001b[0;34m(dataset, metric, model, tokenizer, batch_size, device, column_text, column_summary)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39mfor\u001b[39;00m article_batch, target_batch \u001b[39min\u001b[39;00m tqdm(\n\u001b[1;32m     19\u001b[0m     \u001b[39mzip\u001b[39m(article_batches, target_batches), total\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(article_batches)):\n\u001b[1;32m     21\u001b[0m     inputs \u001b[39m=\u001b[39m tokenizer(article_batch, max_length\u001b[39m=\u001b[39m\u001b[39m1024\u001b[39m,  truncation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, \n\u001b[1;32m     22\u001b[0m                     padding\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmax_length\u001b[39m\u001b[39m\"\u001b[39m, return_tensors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 24\u001b[0m     summaries \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mgenerate(input_ids\u001b[39m=\u001b[39;49minputs[\u001b[39m\"\u001b[39;49m\u001b[39minput_ids\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mto(device),\n\u001b[1;32m     25\u001b[0m                      attention_mask\u001b[39m=\u001b[39;49minputs[\u001b[39m\"\u001b[39;49m\u001b[39mattention_mask\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mto(device), \n\u001b[1;32m     26\u001b[0m                      length_penalty\u001b[39m=\u001b[39;49m\u001b[39m0.8\u001b[39;49m, num_beams\u001b[39m=\u001b[39;49m\u001b[39m8\u001b[39;49m, max_length\u001b[39m=\u001b[39;49m\u001b[39m128\u001b[39;49m)\n\u001b[1;32m     28\u001b[0m     decoded_summaries \u001b[39m=\u001b[39m [tokenizer\u001b[39m.\u001b[39mdecode(s, skip_special_tokens\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, \n\u001b[1;32m     29\u001b[0m                             clean_up_tokenization_spaces\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \n\u001b[1;32m     30\u001b[0m            \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m summaries]\n\u001b[1;32m     31\u001b[0m     decoded_summaries \u001b[39m=\u001b[39m [d\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m<n>\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m decoded_summaries]\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/generation_utils.py:1234\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, repetition_penalty, bad_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, logits_processor, stopping_criteria, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   1230\u001b[0m     input_ids, model_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1231\u001b[0m         input_ids, expand_size\u001b[39m=\u001b[39mnum_beams, is_encoder_decoder\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mis_encoder_decoder, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs\n\u001b[1;32m   1232\u001b[0m     )\n\u001b[1;32m   1233\u001b[0m     \u001b[39m# 12. run beam search\u001b[39;00m\n\u001b[0;32m-> 1234\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbeam_search(\n\u001b[1;32m   1235\u001b[0m         input_ids,\n\u001b[1;32m   1236\u001b[0m         beam_scorer,\n\u001b[1;32m   1237\u001b[0m         logits_processor\u001b[39m=\u001b[39;49mlogits_processor,\n\u001b[1;32m   1238\u001b[0m         stopping_criteria\u001b[39m=\u001b[39;49mstopping_criteria,\n\u001b[1;32m   1239\u001b[0m         pad_token_id\u001b[39m=\u001b[39;49mpad_token_id,\n\u001b[1;32m   1240\u001b[0m         eos_token_id\u001b[39m=\u001b[39;49meos_token_id,\n\u001b[1;32m   1241\u001b[0m         output_scores\u001b[39m=\u001b[39;49moutput_scores,\n\u001b[1;32m   1242\u001b[0m         return_dict_in_generate\u001b[39m=\u001b[39;49mreturn_dict_in_generate,\n\u001b[1;32m   1243\u001b[0m         synced_gpus\u001b[39m=\u001b[39;49msynced_gpus,\n\u001b[1;32m   1244\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_kwargs,\n\u001b[1;32m   1245\u001b[0m     )\n\u001b[1;32m   1247\u001b[0m \u001b[39melif\u001b[39;00m is_beam_sample_gen_mode:\n\u001b[1;32m   1248\u001b[0m     \u001b[39m# 10. prepare logits warper\u001b[39;00m\n\u001b[1;32m   1249\u001b[0m     logits_warper \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_logits_warper(\n\u001b[1;32m   1250\u001b[0m         top_k\u001b[39m=\u001b[39mtop_k, top_p\u001b[39m=\u001b[39mtop_p, temperature\u001b[39m=\u001b[39mtemperature, num_beams\u001b[39m=\u001b[39mnum_beams\n\u001b[1;32m   1251\u001b[0m     )\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/generation_utils.py:1974\u001b[0m, in \u001b[0;36mGenerationMixin.beam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   1970\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m   1972\u001b[0m model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs)\n\u001b[0;32m-> 1974\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\n\u001b[1;32m   1975\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_inputs,\n\u001b[1;32m   1976\u001b[0m     return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1977\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1978\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1979\u001b[0m )\n\u001b[1;32m   1981\u001b[0m \u001b[39mif\u001b[39;00m synced_gpus \u001b[39mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   1982\u001b[0m     cur_len \u001b[39m=\u001b[39m cur_len \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/models/pegasus/modeling_pegasus.py:1406\u001b[0m, in \u001b[0;36mPegasusForConditionalGeneration.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1385\u001b[0m         decoder_input_ids \u001b[39m=\u001b[39m shift_tokens_right(\n\u001b[1;32m   1386\u001b[0m             labels, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mpad_token_id, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mdecoder_start_token_id\n\u001b[1;32m   1387\u001b[0m         )\n\u001b[1;32m   1389\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel(\n\u001b[1;32m   1390\u001b[0m     input_ids,\n\u001b[1;32m   1391\u001b[0m     attention_mask\u001b[39m=\u001b[39mattention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     return_dict\u001b[39m=\u001b[39mreturn_dict,\n\u001b[1;32m   1405\u001b[0m )\n\u001b[0;32m-> 1406\u001b[0m lm_logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlm_head(outputs[\u001b[39m0\u001b[39;49m]) \u001b[39m+\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfinal_logits_bias\n\u001b[1;32m   1408\u001b[0m masked_lm_loss \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1409\u001b[0m \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacty of 14.75 GiB of which 9.06 MiB is free. Process 158553 has 14.74 GiB memory in use. Of the allocated memory 13.52 GiB is allocated by PyTorch, and 213.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# hide_output\n",
    "score = evaluate_summaries_pegasus(dataset_samsum[\"test\"], rouge_metric, model,\n",
    "                                   tokenizer, column_text=\"dialogue\",\n",
    "                                   column_summary=\"summary\", batch_size=8)\n",
    "\n",
    "rouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)\n",
    "pd.DataFrame(rouge_dict, index=[\"pegasus\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# hide_input\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m pd\u001b[39m.\u001b[39mDataFrame(rouge_dict, index\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mpegasus\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# hide_input\n",
    "pd.DataFrame(rouge_dict, index=[\"pegasus\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-Tuning PEGASUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1044 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x350 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d_len = [len(tokenizer.encode(s)) for s in dataset_samsum[\"train\"][\"dialogue\"]]\n",
    "s_len = [len(tokenizer.encode(s)) for s in dataset_samsum[\"train\"][\"summary\"]]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 3.5), sharey=True)\n",
    "axes[0].hist(d_len, bins=20, color=\"C0\", edgecolor=\"C0\")\n",
    "axes[0].set_title(\"Dialogue Token Length\")\n",
    "axes[0].set_xlabel(\"Length\")\n",
    "axes[0].set_ylabel(\"Count\")\n",
    "axes[1].hist(s_len, bins=20, color=\"C0\", edgecolor=\"C0\")\n",
    "axes[1].set_title(\"Summary Token Length\")\n",
    "axes[1].set_xlabel(\"Length\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b5056a9fb534cf2ba4da8c39cdff84e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14732 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9b86915de004c0ca9a910b91bbfa3f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/819 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b216ecddc5dc482cbb740e9f6ba8fe08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/818 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide_output\n",
    "def convert_examples_to_features(example_batch):\n",
    "    input_encodings = tokenizer(example_batch[\"dialogue\"], max_length=1024,\n",
    "                                truncation=True)\n",
    "    \n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        target_encodings = tokenizer(example_batch[\"summary\"], max_length=128,\n",
    "                                     truncation=True)\n",
    "    \n",
    "    return {\"input_ids\": input_encodings[\"input_ids\"],\n",
    "            \"attention_mask\": input_encodings[\"attention_mask\"],\n",
    "            \"labels\": target_encodings[\"input_ids\"]}\n",
    "\n",
    "dataset_samsum_pt = dataset_samsum.map(convert_examples_to_features, \n",
    "                                       batched=True)\n",
    "columns = [\"input_ids\", \"labels\", \"attention_mask\"]\n",
    "dataset_samsum_pt.set_format(type=\"torch\", columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 14732\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 819\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 818\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_samsum_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>decoder_input</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>step</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[PAD]</td>\n",
       "      <td>Transformers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[PAD, Transformers]</td>\n",
       "      <td>are</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[PAD, Transformers, are]</td>\n",
       "      <td>awesome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[PAD, Transformers, are, awesome]</td>\n",
       "      <td>for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[PAD, Transformers, are, awesome, for]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[PAD, Transformers, are, awesome, for, text]</td>\n",
       "      <td>summarization</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     decoder_input          label\n",
       "step                                                             \n",
       "1                                            [PAD]   Transformers\n",
       "2                              [PAD, Transformers]            are\n",
       "3                         [PAD, Transformers, are]        awesome\n",
       "4                [PAD, Transformers, are, awesome]            for\n",
       "5           [PAD, Transformers, are, awesome, for]           text\n",
       "6     [PAD, Transformers, are, awesome, for, text]  summarization"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide_input\n",
    "\n",
    "#id teacher-forcing\n",
    "#alt Decoder input and label alignemt for text generation.\n",
    "#caption Decoder input and label alignemt for text generation.\n",
    "text = ['PAD','Transformers', 'are', 'awesome', 'for', 'text', 'summarization']\n",
    "rows = []\n",
    "for i in range(len(text)-1):\n",
    "    rows.append({'step': i+1, 'decoder_input': text[:i+1], 'label': text[i+1]})\n",
    "pd.DataFrame(rows).set_index('step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "seq2seq_data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m\n",
      "\u001b[0mDataCollatorForSeq2Seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtokenizer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenization_utils_base\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPreTrainedTokenizerBase\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mpadding\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPaddingStrategy\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmax_length\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mpad_to_multiple_of\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mlabel_pad_token_id\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'pt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m     \n",
      "Data collator that will dynamically pad the inputs received, as well as the labels.\n",
      "\n",
      "Args:\n",
      "    tokenizer ([`PreTrainedTokenizer`] or [`PreTrainedTokenizerFast`]):\n",
      "        The tokenizer used for encoding the data.\n",
      "    model ([`PreTrainedModel`]):\n",
      "        The model that is being trained. If set and has the *prepare_decoder_input_ids_from_labels*, use it to\n",
      "        prepare the *decoder_input_ids*\n",
      "\n",
      "        This is useful when using *label_smoothing* to avoid calculating loss twice.\n",
      "    padding (`bool`, `str` or [`~file_utils.PaddingStrategy`], *optional*, defaults to `True`):\n",
      "        Select a strategy to pad the returned sequences (according to the model's padding side and padding index)\n",
      "        among:\n",
      "\n",
      "        - `True` or `'longest'`: Pad to the longest sequence in the batch (or no padding if only a single sequence\n",
      "          is provided).\n",
      "        - `'max_length'`: Pad to a maximum length specified with the argument `max_length` or to the maximum\n",
      "          acceptable input length for the model if that argument is not provided.\n",
      "        - `False` or `'do_not_pad'` (default): No padding (i.e., can output a batch with sequences of different\n",
      "          lengths).\n",
      "    max_length (`int`, *optional*):\n",
      "        Maximum length of the returned list and optionally padding length (see above).\n",
      "    pad_to_multiple_of (`int`, *optional*):\n",
      "        If set will pad the sequence to a multiple of the provided value.\n",
      "\n",
      "        This is especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute capability >=\n",
      "        7.5 (Volta).\n",
      "    label_pad_token_id (`int`, *optional*, defaults to -100):\n",
      "        The id to use when padding the labels (-100 will be automatically ignored by PyTorch loss functions).\n",
      "    return_tensors (`str`):\n",
      "        The type of Tensor to return. Allowable values are \"np\", \"pt\" and \"tf\".\n",
      "\u001b[0;31mFile:\u001b[0m           /home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/data/data_collator.py\n",
      "\u001b[0;31mType:\u001b[0m           type\n",
      "\u001b[0;31mSubclasses:\u001b[0m     "
     ]
    }
   ],
   "source": [
    "DataCollatorForSeq2Seq?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.data.data_collator.DataCollatorForSeq2Seq"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataCollatorForSeq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='pegasus-samsum', num_train_epochs=1, warmup_steps=500,\n",
    "    per_device_train_batch_size=1, per_device_eval_batch_size=1,\n",
    "    weight_decay=0.01, logging_steps=10,# push_to_hub=True,\n",
    "    evaluation_strategy='steps', eval_steps=500, save_steps=1e6,\n",
    "    gradient_accumulation_steps=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #hide_output\n",
    "# from huggingface_hub import notebook_login\n",
    "\n",
    "# notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide_output\n",
    "trainer = Trainer(model=model, args=training_args,\n",
    "                  tokenizer=tokenizer, data_collator=seq2seq_data_collator,\n",
    "                  train_dataset=dataset_samsum_pt[\"train\"], \n",
    "                  eval_dataset=dataset_samsum_pt[\"validation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<transformers.trainer.Trainer at 0x7faae4bd7520>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `PegasusForConditionalGeneration.forward` and have been ignored: id, dialogue, summary.\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 14732\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 16\n",
      "  Total optimization steps = 920\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='920' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 32/920 01:16 < 37:52, 0.39 it/s, Epoch 0.03/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# hide_output\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n\u001b[1;32m      3\u001b[0m score \u001b[39m=\u001b[39m evaluate_summaries_pegasus(\n\u001b[1;32m      4\u001b[0m     dataset_samsum[\u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m], rouge_metric, trainer\u001b[39m.\u001b[39mmodel, tokenizer,\n\u001b[1;32m      5\u001b[0m     batch_size\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, column_text\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdialogue\u001b[39m\u001b[39m\"\u001b[39m, column_summary\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msummary\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m rouge_dict \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m((rn, score[rn]\u001b[39m.\u001b[39mmid\u001b[39m.\u001b[39mfmeasure) \u001b[39mfor\u001b[39;00m rn \u001b[39min\u001b[39;00m rouge_names)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/trainer.py:1370\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1364\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1365\u001b[0m     tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   1367\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   1368\u001b[0m     args\u001b[39m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1369\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[0;32m-> 1370\u001b[0m     \u001b[39mand\u001b[39;00m (torch\u001b[39m.\u001b[39misnan(tr_loss_step) \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39;49misinf(tr_loss_step))\n\u001b[1;32m   1371\u001b[0m ):\n\u001b[1;32m   1372\u001b[0m     \u001b[39m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1373\u001b[0m     tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr_loss \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged)\n\u001b[1;32m   1374\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# hide_output\n",
    "trainer.train()\n",
    "score = evaluate_summaries_pegasus(\n",
    "    dataset_samsum[\"test\"], rouge_metric, trainer.model, tokenizer,\n",
    "    batch_size=2, column_text=\"dialogue\", column_summary=\"summary\")\n",
    "\n",
    "rouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)\n",
    "pd.DataFrame(rouge_dict, index=[f\"pegasus\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pegasus</th>\n",
       "      <td>0.427614</td>\n",
       "      <td>0.200571</td>\n",
       "      <td>0.340648</td>\n",
       "      <td>0.340738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           rouge1    rouge2    rougeL  rougeLsum\n",
       "pegasus  0.427614  0.200571  0.340648   0.340738"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hide_input\n",
    "pd.DataFrame(rouge_dict, index=[f\"pegasus\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to pegasus-samsum-test\n",
      "Configuration saved in pegasus-samsum-test/config.json\n",
      "Model weights saved in pegasus-samsum-test/pytorch_model.bin\n",
      "tokenizer config file saved in pegasus-samsum-test/tokenizer_config.json\n",
      "Special tokens file saved in pegasus-samsum-test/special_tokens_map.json\n",
      "Dropping the following result as it does not have all the necessary field:\n",
      "{'task': {'name': 'Sequence-to-sequence Language Modeling', 'type': 'text2text-generation'}, 'dataset': {'name': 'samsum', 'type': 'samsum', 'args': 'samsum'}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/lvwerra/pegasus-samsum-test/commit/236684ab026115ad5b9eb61f6ddbdaf3f07bddf8'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hide_output\n",
    "trainer.push_to_hub(\"Training complete!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Dialogue Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "import transformers\n",
    "transformers.logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dialogue:\n",
      "Hannah: Hey, do you have Betty's number?\n",
      "Amanda: Lemme check\n",
      "Hannah: <file_gif>\n",
      "Amanda: Sorry, can't find it.\n",
      "Amanda: Ask Larry\n",
      "Amanda: He called her last time we were at the park together\n",
      "Hannah: I don't know him well\n",
      "Hannah: <file_gif>\n",
      "Amanda: Don't be shy, he's very nice\n",
      "Hannah: If you say so..\n",
      "Hannah: I'd rather you texted him\n",
      "Amanda: Just text him 🙂\n",
      "Hannah: Urgh.. Alright\n",
      "Hannah: Bye\n",
      "Amanda: Bye bye\n",
      "\n",
      "Reference Summary:\n",
      "Hannah needs Betty's number but Amanda doesn't have it. She needs to contact\n",
      "Larry.\n",
      "\n",
      "Model Summary:\n",
      "Amanda can't find Betty's number. Larry called Betty last time they were at the\n",
      "park together. Hannah wants Amanda to text Larry instead of calling Betty.\n"
     ]
    }
   ],
   "source": [
    "gen_kwargs = {\"length_penalty\": 0.8, \"num_beams\":8, \"max_length\": 128}\n",
    "sample_text = dataset_samsum[\"test\"][0][\"dialogue\"]\n",
    "reference = dataset_samsum[\"test\"][0][\"summary\"]\n",
    "pipe = pipeline(\"summarization\", model=\"transformersbook/pegasus-samsum\")\n",
    "\n",
    "print(\"Dialogue:\")\n",
    "print(sample_text)\n",
    "print(\"\\nReference Summary:\")\n",
    "print(reference)\n",
    "print(\"\\nModel Summary:\")\n",
    "print(pipe(sample_text, **gen_kwargs)[0][\"summary_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thom, Lewis and Leandro are going to write a book about transformers. Thom\n",
      "helped build a library by Hugging Face. They are going to do it together.\n"
     ]
    }
   ],
   "source": [
    "custom_dialogue = \"\"\"\\\n",
    "Thom: Hi guys, have you heard of transformers?\n",
    "Lewis: Yes, I used them recently!\n",
    "Leandro: Indeed, there is a great library by Hugging Face.\n",
    "Thom: I know, I helped build it ;)\n",
    "Lewis: Cool, maybe we should write a book about it. What do you think?\n",
    "Leandro: Great idea, how hard can it be?!\n",
    "Thom: I am in!\n",
    "Lewis: Awesome, let's do it together!\n",
    "\"\"\"\n",
    "print(pipe(custom_dialogue, **gen_kwargs)[0][\"summary_text\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
